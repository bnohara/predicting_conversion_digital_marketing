{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "937aa645",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Predicting Conversion in Digital Marketing Dataset</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5989f969",
   "metadata": {},
   "source": [
    "<h2>Summary and Goal</h2>\n",
    "\n",
    "The dataset contains marketing data for campaigns and is at the user level. The goal is to predict which users will <b>not</b> convert. Conversion rate in this dataset is pretty high at 88%, so identifying the minority case should be more useful. To increase campaign efficiency, these non-converting users could be added to an exclusion audience. Or, experiments could be run with different marketing strategies to see how to increase the conversion rate for these users.\n",
    "\n",
    "<h2>Assumptions</h2>\n",
    "<ul>\n",
    "    <li>Customer engagement features show the historical lifetime values for that user. These include WebsiteVisits, PagesPerVisit, TimeOnSite, SocialShares, EmailOpens, and EmailClicks.\n",
    "    <li>Marketing-specific metrics also show the historical lifetime values for that user. These include AdSpend, ClickThroughRate, and ConversionRate.\n",
    "    <li>Then the target variable (Conversion) is for a new campaign\n",
    "</ul>\n",
    "\n",
    "<h2>Data Source</h2>\n",
    "\n",
    "Kaggle: https://www.kaggle.com/datasets/rabieelkharoua/predict-conversion-in-digital-marketing-dataset/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "288324f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6fb7799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('digital_marketing_campaign_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "741b5ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Income</th>\n",
       "      <th>CampaignChannel</th>\n",
       "      <th>CampaignType</th>\n",
       "      <th>AdSpend</th>\n",
       "      <th>ClickThroughRate</th>\n",
       "      <th>ConversionRate</th>\n",
       "      <th>WebsiteVisits</th>\n",
       "      <th>PagesPerVisit</th>\n",
       "      <th>TimeOnSite</th>\n",
       "      <th>SocialShares</th>\n",
       "      <th>EmailOpens</th>\n",
       "      <th>EmailClicks</th>\n",
       "      <th>PreviousPurchases</th>\n",
       "      <th>LoyaltyPoints</th>\n",
       "      <th>AdvertisingPlatform</th>\n",
       "      <th>AdvertisingTool</th>\n",
       "      <th>Conversion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8000</td>\n",
       "      <td>56</td>\n",
       "      <td>Female</td>\n",
       "      <td>136912</td>\n",
       "      <td>Social Media</td>\n",
       "      <td>Awareness</td>\n",
       "      <td>6497.870068</td>\n",
       "      <td>0.043919</td>\n",
       "      <td>0.088031</td>\n",
       "      <td>0</td>\n",
       "      <td>2.399017</td>\n",
       "      <td>7.396803</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>688</td>\n",
       "      <td>IsConfid</td>\n",
       "      <td>ToolConfid</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8001</td>\n",
       "      <td>69</td>\n",
       "      <td>Male</td>\n",
       "      <td>41760</td>\n",
       "      <td>Email</td>\n",
       "      <td>Retention</td>\n",
       "      <td>3898.668606</td>\n",
       "      <td>0.155725</td>\n",
       "      <td>0.182725</td>\n",
       "      <td>42</td>\n",
       "      <td>2.917138</td>\n",
       "      <td>5.352549</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3459</td>\n",
       "      <td>IsConfid</td>\n",
       "      <td>ToolConfid</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8002</td>\n",
       "      <td>46</td>\n",
       "      <td>Female</td>\n",
       "      <td>88456</td>\n",
       "      <td>PPC</td>\n",
       "      <td>Awareness</td>\n",
       "      <td>1546.429596</td>\n",
       "      <td>0.277490</td>\n",
       "      <td>0.076423</td>\n",
       "      <td>2</td>\n",
       "      <td>8.223619</td>\n",
       "      <td>13.794901</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2337</td>\n",
       "      <td>IsConfid</td>\n",
       "      <td>ToolConfid</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8003</td>\n",
       "      <td>32</td>\n",
       "      <td>Female</td>\n",
       "      <td>44085</td>\n",
       "      <td>PPC</td>\n",
       "      <td>Conversion</td>\n",
       "      <td>539.525936</td>\n",
       "      <td>0.137611</td>\n",
       "      <td>0.088004</td>\n",
       "      <td>47</td>\n",
       "      <td>4.540939</td>\n",
       "      <td>14.688363</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2463</td>\n",
       "      <td>IsConfid</td>\n",
       "      <td>ToolConfid</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8004</td>\n",
       "      <td>60</td>\n",
       "      <td>Female</td>\n",
       "      <td>83964</td>\n",
       "      <td>PPC</td>\n",
       "      <td>Conversion</td>\n",
       "      <td>1678.043573</td>\n",
       "      <td>0.252851</td>\n",
       "      <td>0.109940</td>\n",
       "      <td>0</td>\n",
       "      <td>2.046847</td>\n",
       "      <td>13.993370</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4345</td>\n",
       "      <td>IsConfid</td>\n",
       "      <td>ToolConfid</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  Age  Gender  Income CampaignChannel CampaignType      AdSpend  \\\n",
       "0        8000   56  Female  136912    Social Media    Awareness  6497.870068   \n",
       "1        8001   69    Male   41760           Email    Retention  3898.668606   \n",
       "2        8002   46  Female   88456             PPC    Awareness  1546.429596   \n",
       "3        8003   32  Female   44085             PPC   Conversion   539.525936   \n",
       "4        8004   60  Female   83964             PPC   Conversion  1678.043573   \n",
       "\n",
       "   ClickThroughRate  ConversionRate  WebsiteVisits  PagesPerVisit  TimeOnSite  \\\n",
       "0          0.043919        0.088031              0       2.399017    7.396803   \n",
       "1          0.155725        0.182725             42       2.917138    5.352549   \n",
       "2          0.277490        0.076423              2       8.223619   13.794901   \n",
       "3          0.137611        0.088004             47       4.540939   14.688363   \n",
       "4          0.252851        0.109940              0       2.046847   13.993370   \n",
       "\n",
       "   SocialShares  EmailOpens  EmailClicks  PreviousPurchases  LoyaltyPoints  \\\n",
       "0            19           6            9                  4            688   \n",
       "1             5           2            7                  2           3459   \n",
       "2             0          11            2                  8           2337   \n",
       "3            89           2            2                  0           2463   \n",
       "4             6           6            6                  8           4345   \n",
       "\n",
       "  AdvertisingPlatform AdvertisingTool  Conversion  \n",
       "0            IsConfid      ToolConfid           1  \n",
       "1            IsConfid      ToolConfid           1  \n",
       "2            IsConfid      ToolConfid           1  \n",
       "3            IsConfid      ToolConfid           1  \n",
       "4            IsConfid      ToolConfid           1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ab13525f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8000 entries, 0 to 7999\n",
      "Data columns (total 20 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   CustomerID           8000 non-null   int64  \n",
      " 1   Age                  8000 non-null   int64  \n",
      " 2   Gender               8000 non-null   object \n",
      " 3   Income               8000 non-null   int64  \n",
      " 4   CampaignChannel      8000 non-null   object \n",
      " 5   CampaignType         8000 non-null   object \n",
      " 6   AdSpend              8000 non-null   float64\n",
      " 7   ClickThroughRate     8000 non-null   float64\n",
      " 8   ConversionRate       8000 non-null   float64\n",
      " 9   WebsiteVisits        8000 non-null   int64  \n",
      " 10  PagesPerVisit        8000 non-null   float64\n",
      " 11  TimeOnSite           8000 non-null   float64\n",
      " 12  SocialShares         8000 non-null   int64  \n",
      " 13  EmailOpens           8000 non-null   int64  \n",
      " 14  EmailClicks          8000 non-null   int64  \n",
      " 15  PreviousPurchases    8000 non-null   int64  \n",
      " 16  LoyaltyPoints        8000 non-null   int64  \n",
      " 17  AdvertisingPlatform  8000 non-null   object \n",
      " 18  AdvertisingTool      8000 non-null   object \n",
      " 19  Conversion           8000 non-null   int64  \n",
      "dtypes: float64(5), int64(10), object(5)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f92ae102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>AdSpend</th>\n",
       "      <th>ClickThroughRate</th>\n",
       "      <th>ConversionRate</th>\n",
       "      <th>WebsiteVisits</th>\n",
       "      <th>PagesPerVisit</th>\n",
       "      <th>TimeOnSite</th>\n",
       "      <th>SocialShares</th>\n",
       "      <th>EmailOpens</th>\n",
       "      <th>EmailClicks</th>\n",
       "      <th>PreviousPurchases</th>\n",
       "      <th>LoyaltyPoints</th>\n",
       "      <th>Conversion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8000.00000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11999.50000</td>\n",
       "      <td>43.625500</td>\n",
       "      <td>84664.196750</td>\n",
       "      <td>5000.944830</td>\n",
       "      <td>0.154829</td>\n",
       "      <td>0.104389</td>\n",
       "      <td>24.751625</td>\n",
       "      <td>5.549299</td>\n",
       "      <td>7.727718</td>\n",
       "      <td>49.799750</td>\n",
       "      <td>9.476875</td>\n",
       "      <td>4.467375</td>\n",
       "      <td>4.485500</td>\n",
       "      <td>2490.268500</td>\n",
       "      <td>0.876500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2309.54541</td>\n",
       "      <td>14.902785</td>\n",
       "      <td>37580.387945</td>\n",
       "      <td>2838.038153</td>\n",
       "      <td>0.084007</td>\n",
       "      <td>0.054878</td>\n",
       "      <td>14.312269</td>\n",
       "      <td>2.607358</td>\n",
       "      <td>4.228218</td>\n",
       "      <td>28.901165</td>\n",
       "      <td>5.711111</td>\n",
       "      <td>2.856564</td>\n",
       "      <td>2.888093</td>\n",
       "      <td>1429.527162</td>\n",
       "      <td>0.329031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8000.00000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>20014.000000</td>\n",
       "      <td>100.054813</td>\n",
       "      <td>0.010005</td>\n",
       "      <td>0.010018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000428</td>\n",
       "      <td>0.501669</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9999.75000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>51744.500000</td>\n",
       "      <td>2523.221165</td>\n",
       "      <td>0.082635</td>\n",
       "      <td>0.056410</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>3.302479</td>\n",
       "      <td>4.068340</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1254.750000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>11999.50000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>84926.500000</td>\n",
       "      <td>5013.440044</td>\n",
       "      <td>0.154505</td>\n",
       "      <td>0.104046</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>5.534257</td>\n",
       "      <td>7.682956</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2497.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13999.25000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>116815.750000</td>\n",
       "      <td>7407.989369</td>\n",
       "      <td>0.228207</td>\n",
       "      <td>0.152077</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>7.835756</td>\n",
       "      <td>11.481468</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3702.250000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15999.00000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>149986.000000</td>\n",
       "      <td>9997.914781</td>\n",
       "      <td>0.299968</td>\n",
       "      <td>0.199995</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>9.999055</td>\n",
       "      <td>14.995311</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4999.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CustomerID          Age         Income      AdSpend  ClickThroughRate  \\\n",
       "count   8000.00000  8000.000000    8000.000000  8000.000000       8000.000000   \n",
       "mean   11999.50000    43.625500   84664.196750  5000.944830          0.154829   \n",
       "std     2309.54541    14.902785   37580.387945  2838.038153          0.084007   \n",
       "min     8000.00000    18.000000   20014.000000   100.054813          0.010005   \n",
       "25%     9999.75000    31.000000   51744.500000  2523.221165          0.082635   \n",
       "50%    11999.50000    43.000000   84926.500000  5013.440044          0.154505   \n",
       "75%    13999.25000    56.000000  116815.750000  7407.989369          0.228207   \n",
       "max    15999.00000    69.000000  149986.000000  9997.914781          0.299968   \n",
       "\n",
       "       ConversionRate  WebsiteVisits  PagesPerVisit   TimeOnSite  \\\n",
       "count     8000.000000    8000.000000    8000.000000  8000.000000   \n",
       "mean         0.104389      24.751625       5.549299     7.727718   \n",
       "std          0.054878      14.312269       2.607358     4.228218   \n",
       "min          0.010018       0.000000       1.000428     0.501669   \n",
       "25%          0.056410      13.000000       3.302479     4.068340   \n",
       "50%          0.104046      25.000000       5.534257     7.682956   \n",
       "75%          0.152077      37.000000       7.835756    11.481468   \n",
       "max          0.199995      49.000000       9.999055    14.995311   \n",
       "\n",
       "       SocialShares   EmailOpens  EmailClicks  PreviousPurchases  \\\n",
       "count   8000.000000  8000.000000  8000.000000        8000.000000   \n",
       "mean      49.799750     9.476875     4.467375           4.485500   \n",
       "std       28.901165     5.711111     2.856564           2.888093   \n",
       "min        0.000000     0.000000     0.000000           0.000000   \n",
       "25%       25.000000     5.000000     2.000000           2.000000   \n",
       "50%       50.000000     9.000000     4.000000           4.000000   \n",
       "75%       75.000000    14.000000     7.000000           7.000000   \n",
       "max       99.000000    19.000000     9.000000           9.000000   \n",
       "\n",
       "       LoyaltyPoints   Conversion  \n",
       "count    8000.000000  8000.000000  \n",
       "mean     2490.268500     0.876500  \n",
       "std      1429.527162     0.329031  \n",
       "min         0.000000     0.000000  \n",
       "25%      1254.750000     1.000000  \n",
       "50%      2497.000000     1.000000  \n",
       "75%      3702.250000     1.000000  \n",
       "max      4999.000000     1.000000  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc1db118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CustomerID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "65a921ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdvertisingPlatform\n",
      "IsConfid    8000\n",
      "Name: count, dtype: int64\n",
      "AdvertisingTool\n",
      "ToolConfid    8000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['AdvertisingPlatform'].value_counts())\n",
    "print(df['AdvertisingTool'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9549599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop features that are either id's or don't vary\n",
    "df_model = df.drop(columns=['CustomerID', 'AdvertisingPlatform', 'AdvertisingTool'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8aed754c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before filtering: 8000\n",
      "Rows with inconsistent data (WebsiteVisits=0 but PagesPerVisit>0 or TimeOnSite>0): 149\n",
      "Rows after filtering: 7851\n",
      "Rows dropped: 149\n"
     ]
    }
   ],
   "source": [
    "# Drop rows where WebsiteVisits is 0 but PagesPerVisit or TimeOnSite > 0\n",
    "# This is logically inconsistent - if no visits, there shouldn't be pages or time on site\n",
    "rows_before = len(df_model)\n",
    "inconsistent_rows = df_model[(df_model['WebsiteVisits'] == 0) & \n",
    "                              ((df_model['PagesPerVisit'] > 0) | (df_model['TimeOnSite'] > 0))]\n",
    "print(f\"Rows before filtering: {rows_before}\")\n",
    "print(f\"Rows with inconsistent data (WebsiteVisits=0 but PagesPerVisit>0 or TimeOnSite>0): {len(inconsistent_rows)}\")\n",
    "\n",
    "df_model = df_model[~((df_model['WebsiteVisits'] == 0) & \n",
    "                       ((df_model['PagesPerVisit'] > 0) | (df_model['TimeOnSite'] > 0)))]\n",
    "\n",
    "rows_after = len(df_model)\n",
    "print(f\"Rows after filtering: {rows_after}\")\n",
    "print(f\"Rows dropped: {rows_before - rows_after}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c174630e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7851 entries, 1 to 7999\n",
      "Data columns (total 17 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Age                7851 non-null   int64  \n",
      " 1   Gender             7851 non-null   object \n",
      " 2   Income             7851 non-null   int64  \n",
      " 3   CampaignChannel    7851 non-null   object \n",
      " 4   CampaignType       7851 non-null   object \n",
      " 5   AdSpend            7851 non-null   float64\n",
      " 6   ClickThroughRate   7851 non-null   float64\n",
      " 7   ConversionRate     7851 non-null   float64\n",
      " 8   WebsiteVisits      7851 non-null   int64  \n",
      " 9   PagesPerVisit      7851 non-null   float64\n",
      " 10  TimeOnSite         7851 non-null   float64\n",
      " 11  SocialShares       7851 non-null   int64  \n",
      " 12  EmailOpens         7851 non-null   int64  \n",
      " 13  EmailClicks        7851 non-null   int64  \n",
      " 14  PreviousPurchases  7851 non-null   int64  \n",
      " 15  LoyaltyPoints      7851 non-null   int64  \n",
      " 16  Conversion         7851 non-null   int64  \n",
      "dtypes: float64(5), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_model.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d16c12c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>AdSpend</th>\n",
       "      <th>ClickThroughRate</th>\n",
       "      <th>ConversionRate</th>\n",
       "      <th>WebsiteVisits</th>\n",
       "      <th>PagesPerVisit</th>\n",
       "      <th>TimeOnSite</th>\n",
       "      <th>SocialShares</th>\n",
       "      <th>EmailOpens</th>\n",
       "      <th>EmailClicks</th>\n",
       "      <th>PreviousPurchases</th>\n",
       "      <th>LoyaltyPoints</th>\n",
       "      <th>Conversion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7851.000000</td>\n",
       "      <td>7851.000000</td>\n",
       "      <td>7851.000000</td>\n",
       "      <td>7851.000000</td>\n",
       "      <td>7851.000000</td>\n",
       "      <td>7851.000000</td>\n",
       "      <td>7851.000000</td>\n",
       "      <td>7851.000000</td>\n",
       "      <td>7851.000000</td>\n",
       "      <td>7851.000000</td>\n",
       "      <td>7851.000000</td>\n",
       "      <td>7851.000000</td>\n",
       "      <td>7851.000000</td>\n",
       "      <td>7851.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>43.620431</td>\n",
       "      <td>84650.945612</td>\n",
       "      <td>5001.503823</td>\n",
       "      <td>0.154510</td>\n",
       "      <td>0.104387</td>\n",
       "      <td>25.221373</td>\n",
       "      <td>5.550547</td>\n",
       "      <td>7.726058</td>\n",
       "      <td>49.887530</td>\n",
       "      <td>9.484779</td>\n",
       "      <td>4.470259</td>\n",
       "      <td>4.486435</td>\n",
       "      <td>2489.470641</td>\n",
       "      <td>0.877977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.915118</td>\n",
       "      <td>37593.190579</td>\n",
       "      <td>2837.227423</td>\n",
       "      <td>0.083965</td>\n",
       "      <td>0.054926</td>\n",
       "      <td>14.031390</td>\n",
       "      <td>2.609545</td>\n",
       "      <td>4.225544</td>\n",
       "      <td>28.889682</td>\n",
       "      <td>5.710298</td>\n",
       "      <td>2.857682</td>\n",
       "      <td>2.885794</td>\n",
       "      <td>1430.015617</td>\n",
       "      <td>0.327333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>20014.000000</td>\n",
       "      <td>100.054813</td>\n",
       "      <td>0.010005</td>\n",
       "      <td>0.010018</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.001882</td>\n",
       "      <td>0.501669</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>51630.500000</td>\n",
       "      <td>2521.206517</td>\n",
       "      <td>0.082243</td>\n",
       "      <td>0.056325</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>3.302288</td>\n",
       "      <td>4.070556</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1254.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>84913.000000</td>\n",
       "      <td>5011.919049</td>\n",
       "      <td>0.153996</td>\n",
       "      <td>0.104086</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>5.534259</td>\n",
       "      <td>7.686031</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2496.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>56.500000</td>\n",
       "      <td>116783.000000</td>\n",
       "      <td>7403.056308</td>\n",
       "      <td>0.227744</td>\n",
       "      <td>0.152128</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>7.842370</td>\n",
       "      <td>11.466218</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3703.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>69.000000</td>\n",
       "      <td>149986.000000</td>\n",
       "      <td>9997.914781</td>\n",
       "      <td>0.299968</td>\n",
       "      <td>0.199995</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>9.999055</td>\n",
       "      <td>14.995311</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4999.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Age         Income      AdSpend  ClickThroughRate  \\\n",
       "count  7851.000000    7851.000000  7851.000000       7851.000000   \n",
       "mean     43.620431   84650.945612  5001.503823          0.154510   \n",
       "std      14.915118   37593.190579  2837.227423          0.083965   \n",
       "min      18.000000   20014.000000   100.054813          0.010005   \n",
       "25%      31.000000   51630.500000  2521.206517          0.082243   \n",
       "50%      43.000000   84913.000000  5011.919049          0.153996   \n",
       "75%      56.500000  116783.000000  7403.056308          0.227744   \n",
       "max      69.000000  149986.000000  9997.914781          0.299968   \n",
       "\n",
       "       ConversionRate  WebsiteVisits  PagesPerVisit   TimeOnSite  \\\n",
       "count     7851.000000    7851.000000    7851.000000  7851.000000   \n",
       "mean         0.104387      25.221373       5.550547     7.726058   \n",
       "std          0.054926      14.031390       2.609545     4.225544   \n",
       "min          0.010018       1.000000       1.001882     0.501669   \n",
       "25%          0.056325      13.000000       3.302288     4.070556   \n",
       "50%          0.104086      25.000000       5.534259     7.686031   \n",
       "75%          0.152128      37.000000       7.842370    11.466218   \n",
       "max          0.199995      49.000000       9.999055    14.995311   \n",
       "\n",
       "       SocialShares   EmailOpens  EmailClicks  PreviousPurchases  \\\n",
       "count   7851.000000  7851.000000  7851.000000        7851.000000   \n",
       "mean      49.887530     9.484779     4.470259           4.486435   \n",
       "std       28.889682     5.710298     2.857682           2.885794   \n",
       "min        0.000000     0.000000     0.000000           0.000000   \n",
       "25%       25.000000     5.000000     2.000000           2.000000   \n",
       "50%       50.000000     9.000000     4.000000           4.000000   \n",
       "75%       75.000000    14.000000     7.000000           7.000000   \n",
       "max       99.000000    19.000000     9.000000           9.000000   \n",
       "\n",
       "       LoyaltyPoints   Conversion  \n",
       "count    7851.000000  7851.000000  \n",
       "mean     2489.470641     0.877977  \n",
       "std      1430.015617     0.327333  \n",
       "min         0.000000     0.000000  \n",
       "25%      1254.500000     1.000000  \n",
       "50%      2496.000000     1.000000  \n",
       "75%      3703.500000     1.000000  \n",
       "max      4999.000000     1.000000  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "71358882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age column converted to age_group\n",
      "\n",
      "age_group value counts:\n",
      "age_group\n",
      "1    1017\n",
      "2    1501\n",
      "3    1544\n",
      "4    1540\n",
      "5    1509\n",
      "6     740\n",
      "Name: count, dtype: int64\n",
      "\n",
      "df_model columns: ['Gender', 'Income', 'CampaignChannel', 'CampaignType', 'AdSpend', 'ClickThroughRate', 'ConversionRate', 'WebsiteVisits', 'PagesPerVisit', 'TimeOnSite', 'SocialShares', 'EmailOpens', 'EmailClicks', 'PreviousPurchases', 'LoyaltyPoints', 'Conversion', 'age_group']\n"
     ]
    }
   ],
   "source": [
    "# Convert Age column to categorical age_group\n",
    "# Age 18-24 --> age_group 1\n",
    "# Age 25-34 --> age_group 2\n",
    "# Age 35-44 --> age_group 3\n",
    "# Age 45-54 --> age_group 4\n",
    "# Age 55-64 --> age_group 5\n",
    "# Age 65+ --> age_group 6\n",
    "\n",
    "def assign_age_group(age):\n",
    "    if 18 <= age <= 24:\n",
    "        return 1\n",
    "    elif 25 <= age <= 34:\n",
    "        return 2\n",
    "    elif 35 <= age <= 44:\n",
    "        return 3\n",
    "    elif 45 <= age <= 54:\n",
    "        return 4\n",
    "    elif 55 <= age <= 64:\n",
    "        return 5\n",
    "    elif age >= 65:\n",
    "        return 6\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Apply the function to create age_group column\n",
    "df_model['age_group'] = df_model['Age'].apply(assign_age_group)\n",
    "\n",
    "# Drop the original Age column and keep age_group as categorical\n",
    "df_model = df_model.drop(columns=['Age'])\n",
    "\n",
    "# Convert age_group to object type (categorical)\n",
    "df_model['age_group'] = df_model['age_group'].astype('object')\n",
    "\n",
    "print(\"Age column converted to age_group\")\n",
    "print(f\"\\nage_group value counts:\")\n",
    "print(df_model['age_group'].value_counts().sort_index())\n",
    "print(f\"\\ndf_model columns: {df_model.columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4f448fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for machine learning\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report, make_scorer\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import numpy as np\n",
    "\n",
    "# Import external boosting libraries (if available)\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    CATBOOST_AVAILABLE = True\n",
    "except ImportError:\n",
    "    CATBOOST_AVAILABLE = False\n",
    "    print(\"Note: CatBoost not available. Install with: pip install catboost\")\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    XGBOOST_AVAILABLE = True\n",
    "except ImportError:\n",
    "    XGBOOST_AVAILABLE = False\n",
    "    print(\"Note: XGBoost not available. Install with: pip install xgboost\")\n",
    "\n",
    "try:\n",
    "    from lightgbm import LGBMClassifier\n",
    "    LIGHTGBM_AVAILABLE = True\n",
    "except ImportError:\n",
    "    LIGHTGBM_AVAILABLE = False\n",
    "    print(\"Note: LightGBM not available. Install with: pip install lightgbm\")\n",
    "\n",
    "# Create custom scorer for F1 score targeting class 0 (non-converters)\n",
    "f1_score_class0 = make_scorer(f1_score, pos_label=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b5a3a288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (7851, 16)\n",
      "Target shape: (7851,)\n",
      "\n",
      "Target distribution:\n",
      "Conversion\n",
      "1    6893\n",
      "0     958\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Target percentage:\n",
      "Conversion\n",
      "1    87.797733\n",
      "0    12.202267\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Prepare data: separate features and target\n",
    "X = df_model.drop(columns=['Conversion'])\n",
    "y = df_model['Conversion']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(y.value_counts())\n",
    "print(f\"\\nTarget percentage:\")\n",
    "print(y.value_counts(normalize=True) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "270072da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: ['Gender', 'CampaignChannel', 'CampaignType', 'age_group']\n",
      "Numerical columns: ['Income', 'AdSpend', 'ClickThroughRate', 'ConversionRate', 'WebsiteVisits', 'PagesPerVisit', 'TimeOnSite', 'SocialShares', 'EmailOpens', 'EmailClicks', 'PreviousPurchases', 'LoyaltyPoints']\n"
     ]
    }
   ],
   "source": [
    "# Identify categorical and numerical columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "print(f\"Categorical columns: {categorical_cols}\")\n",
    "print(f\"Numerical columns: {numerical_cols}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5c2a2121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 6280\n",
      "Test set size: 1571\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4f589a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed training features shape: (6280, 25)\n",
      "Processed test features shape: (1571, 25)\n",
      "\n",
      "======================================================================\n",
      "OVERSAMPLING MINORITY CLASS (Conversion = 0) WITH SMOTE\n",
      "======================================================================\n",
      "\n",
      "Original class distribution in training set:\n",
      "Conversion\n",
      "1    5516\n",
      "0     764\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class percentages:\n",
      "Conversion\n",
      "1    87.834395\n",
      "0    12.165605\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "After SMOTE oversampling:\n",
      "Training set size: 11032 (was 6280)\n",
      "\n",
      "Oversampled class distribution:\n",
      "Conversion\n",
      "1    5516\n",
      "0    5516\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Oversampled class percentages:\n",
      "Conversion\n",
      "1    50.0\n",
      "0    50.0\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create preprocessing pipeline\n",
    "# One-hot encode categorical variables and standardize numerical variables\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_cols)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Apply preprocessing\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "print(f\"Processed training features shape: {X_train_processed.shape}\")\n",
    "print(f\"Processed test features shape: {X_test_processed.shape}\")\n",
    "\n",
    "# Oversample the minority class (Conversion = 0) to address class imbalance\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"OVERSAMPLING MINORITY CLASS (Conversion = 0) WITH SMOTE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nOriginal class distribution in training set:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"\\nClass percentages:\")\n",
    "print(y_train.value_counts(normalize=True) * 100)\n",
    "\n",
    "# Apply SMOTE to oversample the minority class\n",
    "smote = SMOTE(random_state=42, sampling_strategy='auto')\n",
    "X_train_oversampled, y_train_oversampled = smote.fit_resample(X_train_processed, y_train)\n",
    "\n",
    "print(f\"\\nAfter SMOTE oversampling:\")\n",
    "print(f\"Training set size: {X_train_oversampled.shape[0]} (was {X_train_processed.shape[0]})\")\n",
    "print(f\"\\nOversampled class distribution:\")\n",
    "print(pd.Series(y_train_oversampled).value_counts())\n",
    "print(f\"\\nOversampled class percentages:\")\n",
    "print(pd.Series(y_train_oversampled).value_counts(normalize=True) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "59292b57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Optimizing Logistic Regression...\n",
      "============================================================\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bnoha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: FitFailedWarning: \n",
      "30 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\bnoha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\bnoha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\bnoha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1218, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\bnoha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\bnoha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [       nan 0.74269637        nan 0.74269637        nan 0.74317812\n",
      "        nan 0.74317812        nan 0.74367384        nan 0.74367384]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters for Logistic Regression:\n",
      "{'C': 10, 'class_weight': None, 'penalty': 'l2'}\n",
      "Best CV F1 Score (Class 0): 0.7437\n",
      "\n",
      "============================================================\n",
      "Performance Metrics for Class 0 (Non-Converters):\n",
      "============================================================\n",
      "Train Precision (Class 0): 0.2750\n",
      "Test Precision (Class 0): 0.2790\n",
      "Train Recall (Class 0): 0.7199\n",
      "Test Recall (Class 0): 0.7320\n",
      "Train F1 Score (Class 0): 0.3980\n",
      "Test F1 Score (Class 0): 0.4040\n",
      "\n",
      "============================================================\n",
      "Other Metrics:\n",
      "============================================================\n",
      "Train Accuracy: 0.7350\n",
      "Test Accuracy: 0.7333\n",
      "Train F1 Score (Class 1): 0.8301\n",
      "Test F1 Score (Class 1): 0.8282\n",
      "Train ROC-AUC: 0.7949\n",
      "Test ROC-AUC: 0.7994\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[ 142   52]\n",
      " [ 367 1010]]\n",
      "\n",
      "============================================================\n",
      "Optimizing Decision Tree...\n",
      "============================================================\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "\n",
      "Best parameters for Decision Tree:\n",
      "{'max_depth': None, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best CV F1 Score (Class 0): 0.8542\n",
      "\n",
      "============================================================\n",
      "Performance Metrics for Class 0 (Non-Converters):\n",
      "============================================================\n",
      "Train Precision (Class 0): 1.0000\n",
      "Test Precision (Class 0): 0.2784\n",
      "Train Recall (Class 0): 1.0000\n",
      "Test Recall (Class 0): 0.3918\n",
      "Train F1 Score (Class 0): 1.0000\n",
      "Test F1 Score (Class 0): 0.3255\n",
      "\n",
      "============================================================\n",
      "Other Metrics:\n",
      "============================================================\n",
      "Train Accuracy: 1.0000\n",
      "Test Accuracy: 0.7995\n",
      "Train F1 Score (Class 1): 1.0000\n",
      "Test F1 Score (Class 1): 0.8822\n",
      "Train ROC-AUC: 1.0000\n",
      "Test ROC-AUC: 0.6243\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[  76  118]\n",
      " [ 197 1180]]\n",
      "\n",
      "============================================================\n",
      "Optimizing Random Forest...\n",
      "============================================================\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "\n",
      "Best parameters for Random Forest:\n",
      "{'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best CV F1 Score (Class 0): 0.9470\n",
      "\n",
      "============================================================\n",
      "Performance Metrics for Class 0 (Non-Converters):\n",
      "============================================================\n",
      "Train Precision (Class 0): 1.0000\n",
      "Test Precision (Class 0): 0.8116\n",
      "Train Recall (Class 0): 1.0000\n",
      "Test Recall (Class 0): 0.2887\n",
      "Train F1 Score (Class 0): 1.0000\n",
      "Test F1 Score (Class 0): 0.4259\n",
      "\n",
      "============================================================\n",
      "Other Metrics:\n",
      "============================================================\n",
      "Train Accuracy: 1.0000\n",
      "Test Accuracy: 0.9039\n",
      "Train F1 Score (Class 1): 1.0000\n",
      "Test F1 Score (Class 1): 0.9476\n",
      "Train ROC-AUC: 1.0000\n",
      "Test ROC-AUC: 0.8013\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[  56  138]\n",
      " [  13 1364]]\n",
      "\n",
      "============================================================\n",
      "Optimizing Gradient Boosting...\n",
      "============================================================\n",
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n",
      "\n",
      "Best parameters for Gradient Boosting:\n",
      "{'learning_rate': 0.1, 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100, 'n_iter_no_change': 5, 'subsample': 1.0}\n",
      "Best CV F1 Score (Class 0): 0.9069\n",
      "\n",
      "============================================================\n",
      "Performance Metrics for Class 0 (Non-Converters):\n",
      "============================================================\n",
      "Train Precision (Class 0): 0.9955\n",
      "Test Precision (Class 0): 0.8810\n",
      "Train Recall (Class 0): 0.8665\n",
      "Test Recall (Class 0): 0.3814\n",
      "Train F1 Score (Class 0): 0.9265\n",
      "Test F1 Score (Class 0): 0.5324\n",
      "\n",
      "============================================================\n",
      "Other Metrics:\n",
      "============================================================\n",
      "Train Accuracy: 0.9833\n",
      "Test Accuracy: 0.9173\n",
      "Train F1 Score (Class 1): 0.9906\n",
      "Test F1 Score (Class 1): 0.9546\n",
      "Train ROC-AUC: 0.9909\n",
      "Test ROC-AUC: 0.7995\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[  74  120]\n",
      " [  10 1367]]\n",
      "\n",
      "============================================================\n",
      "Optimizing AdaBoost...\n",
      "============================================================\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bnoha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: FitFailedWarning: \n",
      "45 fits failed out of a total of 90.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\bnoha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\bnoha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\bnoha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\bnoha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'algorithm' parameter of AdaBoostClassifier must be a str among {'SAMME'}. Got 'SAMME.R' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\bnoha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [0.76214271 0.78729757 0.81142511 0.83478315 0.85976444 0.8811619\n",
      " 0.87154138 0.8821523  0.88182747        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\bnoha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters for AdaBoost:\n",
      "{'algorithm': 'SAMME', 'learning_rate': 1.0, 'n_estimators': 100}\n",
      "Best CV F1 Score (Class 0): 0.8822\n",
      "\n",
      "============================================================\n",
      "Performance Metrics for Class 0 (Non-Converters):\n",
      "============================================================\n",
      "Train Precision (Class 0): 0.6596\n",
      "Test Precision (Class 0): 0.6644\n",
      "Train Recall (Class 0): 0.5301\n",
      "Test Recall (Class 0): 0.5103\n",
      "Train F1 Score (Class 0): 0.5878\n",
      "Test F1 Score (Class 0): 0.5773\n",
      "\n",
      "============================================================\n",
      "Other Metrics:\n",
      "============================================================\n",
      "Train Accuracy: 0.9096\n",
      "Test Accuracy: 0.9077\n",
      "Train F1 Score (Class 1): 0.9492\n",
      "Test F1 Score (Class 1): 0.9482\n",
      "Train ROC-AUC: 0.8338\n",
      "Test ROC-AUC: 0.8181\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[  99   95]\n",
      " [  50 1327]]\n",
      "\n",
      "============================================================\n",
      "Optimizing CatBoost...\n",
      "============================================================\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      "Best parameters for CatBoost:\n",
      "{'depth': 7, 'iterations': 200, 'l2_leaf_reg': 1, 'learning_rate': 0.2}\n",
      "Best CV F1 Score (Class 0): 0.8890\n",
      "\n",
      "============================================================\n",
      "Performance Metrics for Class 0 (Non-Converters):\n",
      "============================================================\n",
      "Train Precision (Class 0): 1.0000\n",
      "Test Precision (Class 0): 0.8452\n",
      "Train Recall (Class 0): 0.9948\n",
      "Test Recall (Class 0): 0.3660\n",
      "Train F1 Score (Class 0): 0.9974\n",
      "Test F1 Score (Class 0): 0.5108\n",
      "\n",
      "============================================================\n",
      "Other Metrics:\n",
      "============================================================\n",
      "Train Accuracy: 0.9994\n",
      "Test Accuracy: 0.9134\n",
      "Train F1 Score (Class 1): 0.9996\n",
      "Test F1 Score (Class 1): 0.9525\n",
      "Train ROC-AUC: 1.0000\n",
      "Test ROC-AUC: 0.7957\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[  71  123]\n",
      " [  13 1364]]\n",
      "\n",
      "============================================================\n",
      "Optimizing XGBoost...\n",
      "============================================================\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bnoha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [14:07:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters for XGBoost:\n",
      "{'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 100, 'subsample': 0.8}\n",
      "Best CV F1 Score (Class 0): 0.9038\n",
      "\n",
      "============================================================\n",
      "Performance Metrics for Class 0 (Non-Converters):\n",
      "============================================================\n",
      "Train Precision (Class 0): 0.9984\n",
      "Test Precision (Class 0): 0.9091\n",
      "Train Recall (Class 0): 0.8259\n",
      "Test Recall (Class 0): 0.4124\n",
      "Train F1 Score (Class 0): 0.9040\n",
      "Test F1 Score (Class 0): 0.5674\n",
      "\n",
      "============================================================\n",
      "Other Metrics:\n",
      "============================================================\n",
      "Train Accuracy: 0.9787\n",
      "Test Accuracy: 0.9223\n",
      "Train F1 Score (Class 1): 0.9880\n",
      "Test F1 Score (Class 1): 0.9573\n",
      "Train ROC-AUC: 0.9979\n",
      "Test ROC-AUC: 0.8001\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[  80  114]\n",
      " [   8 1369]]\n",
      "\n",
      "============================================================\n",
      "Optimizing LightGBM...\n",
      "============================================================\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "\n",
      "Best parameters for LightGBM:\n",
      "{'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 100, 'subsample': 0.8}\n",
      "Best CV F1 Score (Class 0): 0.8951\n",
      "\n",
      "============================================================\n",
      "Performance Metrics for Class 0 (Non-Converters):\n",
      "============================================================\n",
      "Train Precision (Class 0): 0.9862\n",
      "Test Precision (Class 0): 0.8333\n",
      "Train Recall (Class 0): 0.7461\n",
      "Test Recall (Class 0): 0.4381\n",
      "Train F1 Score (Class 0): 0.8495\n",
      "Test F1 Score (Class 0): 0.5743\n",
      "\n",
      "============================================================\n",
      "Other Metrics:\n",
      "============================================================\n",
      "Train Accuracy: 0.9678\n",
      "Test Accuracy: 0.9198\n",
      "Train F1 Score (Class 1): 0.9820\n",
      "Test F1 Score (Class 1): 0.9557\n",
      "Train ROC-AUC: 0.9854\n",
      "Test ROC-AUC: 0.8061\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[  85  109]\n",
      " [  17 1360]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bnoha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\bnoha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\bnoha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\bnoha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define models and their hyperparameter grids for optimization\n",
    "# We'll use GridSearchCV with F1 score as the scoring metric\n",
    "# Note: Models are trained on oversampled data (X_train_oversampled, y_train_oversampled)\n",
    "# but evaluated on original data for fair comparison\n",
    "\n",
    "param_grids = {\n",
    "    'Logistic Regression': {\n",
    "        'C': [0.1, 1, 10],  # Reduced to 3 key values\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'class_weight': [None, 'balanced']\n",
    "        # Total: 3 * 2 * 2 = 12 combinations\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'max_depth': [5, 10, 20, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'max_features': ['sqrt', None]\n",
    "        # Total: 4 * 3 * 3 * 2 = 72 combinations\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [10, 20, None],  # Reduced to 3 values\n",
    "        'min_samples_split': [2, 5],  # Reduced to 2 values\n",
    "        'min_samples_leaf': [1, 2],  # Reduced to 2 values\n",
    "        'max_features': ['sqrt', None]  # Reduced to 2 values\n",
    "        # Total: 3 * 3 * 2 * 2 * 2 = 72 combinations (down from 324)\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'n_estimators': [100, 200],  # Early stopping will handle this\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.1, 0.2],  # Reduced to 2 values\n",
    "        'min_samples_split': [2, 5],  # Reduced to 2 values\n",
    "        'n_iter_no_change': [5, 10],  # Early stopping\n",
    "        'subsample': [0.8, 1.0],  # Regularization\n",
    "        'max_features': ['sqrt', None]  # Regularization\n",
    "        # Total: 2 * 3 * 2 * 2 * 2 * 2 * 2 = 96 combinations (down from 216)\n",
    "    },\n",
    "    'AdaBoost': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.1, 0.5, 1.0],\n",
    "        'algorithm': ['SAMME', 'SAMME.R']\n",
    "        # Total: 3 * 3 * 2 = 18 combinations\n",
    "    }\n",
    "}\n",
    "\n",
    "# Add external boosting libraries if available\n",
    "# Note: early_stopping_rounds removed from param_grids as it requires eval_set which GridSearchCV doesn't provide\n",
    "if CATBOOST_AVAILABLE:\n",
    "    param_grids['CatBoost'] = {\n",
    "        'iterations': [100, 200],\n",
    "        'depth': [3, 5, 7],\n",
    "        'learning_rate': [0.1, 0.2],\n",
    "        'l2_leaf_reg': [1, 3]  # Regularization\n",
    "        # Total: 2 * 3 * 2 * 2 = 24 combinations\n",
    "    }\n",
    "\n",
    "if XGBOOST_AVAILABLE:\n",
    "    param_grids['XGBoost'] = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.1, 0.2],\n",
    "        'subsample': [0.8, 1.0],  # Regularization\n",
    "        'colsample_bytree': [0.8, 1.0]  # Regularization\n",
    "        # Total: 2 * 3 * 2 * 2 * 2 = 48 combinations\n",
    "    }\n",
    "\n",
    "if LIGHTGBM_AVAILABLE:\n",
    "    param_grids['LightGBM'] = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.1, 0.2],\n",
    "        'subsample': [0.8, 1.0],  # Regularization\n",
    "        'colsample_bytree': [0.8, 1.0]  # Regularization\n",
    "        # Total: 2 * 3 * 2 * 2 * 2 = 48 combinations\n",
    "    }\n",
    "\n",
    "# Base models\n",
    "# Note: Gradient Boosting and external libraries will use early stopping if configured in param_grid\n",
    "base_models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42, warm_start=False),\n",
    "    'AdaBoost': AdaBoostClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Add external boosting libraries if available\n",
    "if CATBOOST_AVAILABLE:\n",
    "    base_models['CatBoost'] = CatBoostClassifier(\n",
    "        random_state=42, \n",
    "        verbose=False, \n",
    "        allow_writing_files=False,\n",
    "        early_stopping_rounds=10  # Set as fixed parameter instead of in grid\n",
    "    )\n",
    "\n",
    "if XGBOOST_AVAILABLE:\n",
    "    base_models['XGBoost'] = XGBClassifier(\n",
    "        random_state=42, \n",
    "        eval_metric='logloss', \n",
    "        use_label_encoder=False,\n",
    "        tree_method='hist'  # Faster and more memory efficient\n",
    "    )\n",
    "\n",
    "if LIGHTGBM_AVAILABLE:\n",
    "    base_models['LightGBM'] = LGBMClassifier(random_state=42, verbose=-1)\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Optimize and evaluate each model\n",
    "for name, base_model in base_models.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Optimizing {name}...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Perform grid search with F1 score for class 0 (non-converters) as the scoring metric\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=base_model,\n",
    "        param_grid=param_grids[name],\n",
    "        scoring=f1_score_class0,  # Use custom scorer targeting class 0\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Use oversampled training data for model training\n",
    "    grid_search.fit(X_train_oversampled, y_train_oversampled)\n",
    "    \n",
    "    # Get the best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    print(f\"\\nBest parameters for {name}:\")\n",
    "    print(grid_search.best_params_)\n",
    "    print(f\"Best CV F1 Score (Class 0): {grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    # Make predictions (both class predictions and probability predictions)\n",
    "    y_train_pred = best_model.predict(X_train_processed)\n",
    "    y_test_pred = best_model.predict(X_test_processed)\n",
    "    y_train_proba = best_model.predict_proba(X_train_processed)[:, 1]\n",
    "    y_test_proba = best_model.predict_proba(X_test_processed)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Calculate precision, recall, and F1 for class 0 (non-converters)\n",
    "    train_precision_class0 = precision_score(y_train, y_train_pred, pos_label=0, zero_division=0)\n",
    "    test_precision_class0 = precision_score(y_test, y_test_pred, pos_label=0, zero_division=0)\n",
    "    train_recall_class0 = recall_score(y_train, y_train_pred, pos_label=0, zero_division=0)\n",
    "    test_recall_class0 = recall_score(y_test, y_test_pred, pos_label=0, zero_division=0)\n",
    "    train_f1_class0 = f1_score(y_train, y_train_pred, pos_label=0, zero_division=0)\n",
    "    test_f1_class0 = f1_score(y_test, y_test_pred, pos_label=0, zero_division=0)\n",
    "    \n",
    "    # Also calculate metrics for class 1 for comparison\n",
    "    train_precision_class1 = precision_score(y_train, y_train_pred, pos_label=1, zero_division=0)\n",
    "    test_precision_class1 = precision_score(y_test, y_test_pred, pos_label=1, zero_division=0)\n",
    "    train_recall_class1 = recall_score(y_train, y_train_pred, pos_label=1, zero_division=0)\n",
    "    test_recall_class1 = recall_score(y_test, y_test_pred, pos_label=1, zero_division=0)\n",
    "    train_f1_class1 = f1_score(y_train, y_train_pred, pos_label=1, zero_division=0)\n",
    "    test_f1_class1 = f1_score(y_test, y_test_pred, pos_label=1, zero_division=0)\n",
    "    \n",
    "    train_roc_auc = roc_auc_score(y_train, y_train_proba)\n",
    "    test_roc_auc = roc_auc_score(y_test, y_test_proba)\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'model': best_model,\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'cv_f1_score_class0': grid_search.best_score_,\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'train_precision_class0': train_precision_class0,\n",
    "        'test_precision_class0': test_precision_class0,\n",
    "        'train_recall_class0': train_recall_class0,\n",
    "        'test_recall_class0': test_recall_class0,\n",
    "        'train_f1_class0': train_f1_class0,\n",
    "        'test_f1_class0': test_f1_class0,\n",
    "        'train_precision_class1': train_precision_class1,\n",
    "        'test_precision_class1': test_precision_class1,\n",
    "        'train_recall_class1': train_recall_class1,\n",
    "        'test_recall_class1': test_recall_class1,\n",
    "        'train_f1_class1': train_f1_class1,\n",
    "        'test_f1_class1': test_f1_class1,\n",
    "        'train_roc_auc': train_roc_auc,\n",
    "        'test_roc_auc': test_roc_auc\n",
    "    }\n",
    "    \n",
    "    # Print results - focusing on class 0 (non-converters)\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Performance Metrics for Class 0 (Non-Converters):\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Train Precision (Class 0): {train_precision_class0:.4f}\")\n",
    "    print(f\"Test Precision (Class 0): {test_precision_class0:.4f}\")\n",
    "    print(f\"Train Recall (Class 0): {train_recall_class0:.4f}\")\n",
    "    print(f\"Test Recall (Class 0): {test_recall_class0:.4f}\")\n",
    "    print(f\"Train F1 Score (Class 0): {train_f1_class0:.4f}\")\n",
    "    print(f\"Test F1 Score (Class 0): {test_f1_class0:.4f}\")\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Other Metrics:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Train Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Train F1 Score (Class 1): {train_f1_class1:.4f}\")\n",
    "    print(f\"Test F1 Score (Class 1): {test_f1_class1:.4f}\")\n",
    "    print(f\"Train ROC-AUC: {train_roc_auc:.4f}\")\n",
    "    print(f\"Test ROC-AUC: {test_roc_auc:.4f}\")\n",
    "    \n",
    "    # Print confusion matrix for test set\n",
    "    print(f\"\\nTest Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "25dd4445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "MODEL COMPARISON SUMMARY (Sorted by Test F1 Score for Class 0 - Non-Converters)\n",
      "====================================================================================================\n",
      "              Model  CV F1 (Class 0)  Test Precision (Class 0)  Test Recall (Class 0)  Test F1 (Class 0)  Test Accuracy  Test F1 (Class 1)  Test ROC-AUC\n",
      "           AdaBoost         0.882152                  0.664430               0.510309           0.577259       0.907702           0.948196      0.818102\n",
      "           LightGBM         0.895059                  0.833333               0.438144           0.574324       0.919796           0.955727      0.806074\n",
      "            XGBoost         0.903821                  0.909091               0.412371           0.567376       0.922342           0.957343      0.800130\n",
      "  Gradient Boosting         0.906938                  0.880952               0.381443           0.532374       0.917250           0.954609      0.799467\n",
      "           CatBoost         0.888999                  0.845238               0.365979           0.510791       0.913431           0.952514      0.795750\n",
      "      Random Forest         0.946979                  0.811594               0.288660           0.425856       0.903883           0.947551      0.801339\n",
      "Logistic Regression         0.743674                  0.278978               0.731959           0.403983       0.733291           0.828208      0.799437\n",
      "      Decision Tree         0.854212                  0.278388               0.391753           0.325482       0.799491           0.882243      0.624344\n",
      "\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Create a comparison DataFrame - focusing on Class 0 (non-converters)\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'CV F1 (Class 0)': [results[m]['cv_f1_score_class0'] for m in results.keys()],\n",
    "    'Test Precision (Class 0)': [results[m]['test_precision_class0'] for m in results.keys()],\n",
    "    'Test Recall (Class 0)': [results[m]['test_recall_class0'] for m in results.keys()],\n",
    "    'Test F1 (Class 0)': [results[m]['test_f1_class0'] for m in results.keys()],\n",
    "    'Test Accuracy': [results[m]['test_accuracy'] for m in results.keys()],\n",
    "    'Test F1 (Class 1)': [results[m]['test_f1_class1'] for m in results.keys()],\n",
    "    'Test ROC-AUC': [results[m]['test_roc_auc'] for m in results.keys()]\n",
    "})\n",
    "\n",
    "# Sort by Test F1 Score for Class 0 (best first) - this is our primary metric\n",
    "comparison_df = comparison_df.sort_values('Test F1 (Class 0)', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"MODEL COMPARISON SUMMARY (Sorted by Test F1 Score for Class 0 - Non-Converters)\")\n",
    "print(\"=\"*100)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c7e55349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "COMPARING MODELS: WITH vs WITHOUT OVERSAMPLING\n",
      "======================================================================\n",
      "\n",
      "Training models WITHOUT oversampling...\n",
      "\n",
      "============================================================\n",
      "Training Logistic Regression WITHOUT oversampling...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bnoha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: FitFailedWarning: \n",
      "30 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\bnoha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\bnoha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\bnoha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1218, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\bnoha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\bnoha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [       nan 0.27133888        nan 0.38748977        nan 0.29465898\n",
      "        nan 0.38793584        nan 0.2954234         nan 0.38862065]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 10, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "Best CV F1 Score (Class 0): 0.3886\n",
      "\n",
      "============================================================\n",
      "Training Decision Tree WITHOUT oversampling...\n",
      "============================================================\n",
      "Best parameters: {'max_depth': 10, 'max_features': None, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "Best CV F1 Score (Class 0): 0.3700\n",
      "\n",
      "============================================================\n",
      "Training Random Forest WITHOUT oversampling...\n",
      "============================================================\n",
      "Best parameters: {'max_depth': None, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Best CV F1 Score (Class 0): 0.3768\n",
      "\n",
      "============================================================\n",
      "Training Gradient Boosting WITHOUT oversampling...\n",
      "============================================================\n",
      "Best parameters: {'learning_rate': 0.2, 'max_depth': 3, 'max_features': None, 'min_samples_split': 5, 'n_estimators': 100, 'n_iter_no_change': 10, 'subsample': 1.0}\n",
      "Best CV F1 Score (Class 0): 0.5163\n",
      "\n",
      "============================================================\n",
      "Training AdaBoost WITHOUT oversampling...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bnoha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: FitFailedWarning: \n",
      "45 fits failed out of a total of 90.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\bnoha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\bnoha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\bnoha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\bnoha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'algorithm' parameter of AdaBoostClassifier must be a str among {'SAMME'}. Got 'SAMME.R' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\bnoha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [0.         0.0129535  0.09903758 0.1990739  0.23692846 0.2549297\n",
      " 0.33161002 0.35635147 0.38135875        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\bnoha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'algorithm': 'SAMME', 'learning_rate': 1.0, 'n_estimators': 200}\n",
      "Best CV F1 Score (Class 0): 0.3814\n",
      "\n",
      "============================================================\n",
      "Training CatBoost WITHOUT oversampling...\n",
      "============================================================\n",
      "Best parameters: {'depth': 3, 'iterations': 100, 'l2_leaf_reg': 1, 'learning_rate': 0.2}\n",
      "Best CV F1 Score (Class 0): 0.5771\n",
      "\n",
      "============================================================\n",
      "Training XGBoost WITHOUT oversampling...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bnoha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [14:13:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Best CV F1 Score (Class 0): 0.5670\n",
      "\n",
      "============================================================\n",
      "Training LightGBM WITHOUT oversampling...\n",
      "============================================================\n",
      "Best parameters: {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Best CV F1 Score (Class 0): 0.5583\n",
      "\n",
      "====================================================================================================\n",
      "COMPARISON: WITH OVERSAMPLING vs WITHOUT OVERSAMPLING\n",
      "====================================================================================================\n",
      "              Model  With Oversampling - Test F1 (Class 0)  With Oversampling - Test Precision (Class 0)  With Oversampling - Test Recall (Class 0)  Without Oversampling - Test F1 (Class 0)  Without Oversampling - Test Precision (Class 0)  Without Oversampling - Test Recall (Class 0)  F1 Improvement  Recall Improvement  Precision Change\n",
      "Logistic Regression                               0.403983                                      0.278978                                   0.731959                                  0.396648                                         0.272031                                      0.731959        0.007335            0.000000          0.006948\n",
      "      Decision Tree                               0.325482                                      0.278388                                   0.391753                                  0.384824                                         0.405714                                      0.365979       -0.059342            0.025773         -0.127326\n",
      "      Random Forest                               0.425856                                      0.811594                                   0.288660                                  0.400000                                         0.787879                                      0.268041        0.025856            0.020619          0.023715\n",
      "  Gradient Boosting                               0.532374                                      0.880952                                   0.381443                                  0.577320                                         0.865979                                      0.432990       -0.044945           -0.051546          0.014973\n",
      "           AdaBoost                               0.577259                                      0.664430                                   0.510309                                  0.401639                                         0.980000                                      0.252577        0.175620            0.257732         -0.315570\n",
      "           CatBoost                               0.510791                                      0.845238                                   0.365979                                  0.601399                                         0.934783                                      0.443299       -0.090607           -0.077320         -0.089545\n",
      "            XGBoost                               0.567376                                      0.909091                                   0.412371                                  0.612676                                         0.966667                                      0.448454       -0.045300           -0.036082         -0.057576\n",
      "           LightGBM                               0.574324                                      0.833333                                   0.438144                                  0.628378                                         0.911765                                      0.479381       -0.054054           -0.041237         -0.078431\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "======================================================================\n",
      "SUMMARY: Which approach performs better?\n",
      "======================================================================\n",
      "Logistic Regression: Oversampling is BETTER (F1 improvement: +0.0073)\n",
      "Decision Tree: No oversampling is BETTER (F1 difference: -0.0593)\n",
      "Random Forest: Oversampling is BETTER (F1 improvement: +0.0259)\n",
      "Gradient Boosting: No oversampling is BETTER (F1 difference: -0.0449)\n",
      "AdaBoost: Oversampling is BETTER (F1 improvement: +0.1756)\n",
      "CatBoost: No oversampling is BETTER (F1 difference: -0.0906)\n",
      "XGBoost: No oversampling is BETTER (F1 difference: -0.0453)\n",
      "LightGBM: No oversampling is BETTER (F1 difference: -0.0541)\n",
      "\n",
      "Best Test F1 Score WITH oversampling: 0.5773\n",
      "Best Test F1 Score WITHOUT oversampling: 0.6284\n",
      "\n",
      " OVERALL WINNER: No oversampling (improvement: +0.0511)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bnoha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\bnoha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\bnoha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Compare models trained with and without oversampling\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARING MODELS: WITH vs WITHOUT OVERSAMPLING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Store results from oversampled models (already trained above)\n",
    "results_oversampled = results.copy()\n",
    "\n",
    "# Now train models WITHOUT oversampling for comparison\n",
    "print(\"\\nTraining models WITHOUT oversampling...\")\n",
    "results_no_oversampling = {}\n",
    "\n",
    "for name, base_model in base_models.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {name} WITHOUT oversampling...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Perform grid search with F1 score for class 0 (non-converters) as the scoring metric\n",
    "    # Train on original (non-oversampled) data\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=base_model,\n",
    "        param_grid=param_grids[name],\n",
    "        scoring=f1_score_class0,  # Use custom scorer targeting class 0\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        verbose=0  # Set to 0 to reduce output\n",
    "    )\n",
    "    \n",
    "    # Use original training data (no oversampling)\n",
    "    grid_search.fit(X_train_processed, y_train)\n",
    "    \n",
    "    # Get the best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best CV F1 Score (Class 0): {grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    # Make predictions\n",
    "    y_train_pred = best_model.predict(X_train_processed)\n",
    "    y_test_pred = best_model.predict(X_test_processed)\n",
    "    \n",
    "    # Calculate metrics for class 0\n",
    "    train_f1_class0 = f1_score(y_train, y_train_pred, pos_label=0, zero_division=0)\n",
    "    test_f1_class0 = f1_score(y_test, y_test_pred, pos_label=0, zero_division=0)\n",
    "    train_precision_class0 = precision_score(y_train, y_train_pred, pos_label=0, zero_division=0)\n",
    "    test_precision_class0 = precision_score(y_test, y_test_pred, pos_label=0, zero_division=0)\n",
    "    train_recall_class0 = recall_score(y_train, y_train_pred, pos_label=0, zero_division=0)\n",
    "    test_recall_class0 = recall_score(y_test, y_test_pred, pos_label=0, zero_division=0)\n",
    "    \n",
    "    # Store results (including the model object)\n",
    "    results_no_oversampling[name] = {\n",
    "        'model': best_model,\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'cv_f1_score_class0': grid_search.best_score_,\n",
    "        'train_f1_class0': train_f1_class0,\n",
    "        'test_f1_class0': test_f1_class0,\n",
    "        'train_precision_class0': train_precision_class0,\n",
    "        'test_precision_class0': test_precision_class0,\n",
    "        'train_recall_class0': train_recall_class0,\n",
    "        'test_recall_class0': test_recall_class0,\n",
    "        'train_accuracy': accuracy_score(y_train, y_train_pred),\n",
    "        'test_accuracy': accuracy_score(y_test, y_test_pred),\n",
    "        'train_f1_class1': f1_score(y_train, y_train_pred, pos_label=1, zero_division=0),\n",
    "        'test_f1_class1': f1_score(y_test, y_test_pred, pos_label=1, zero_division=0),\n",
    "        'test_roc_auc': roc_auc_score(y_test, best_model.predict_proba(X_test_processed)[:, 1])\n",
    "    }\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_oversampling = pd.DataFrame({\n",
    "    'Model': list(results_oversampled.keys()),\n",
    "    'With Oversampling - Test F1 (Class 0)': [results_oversampled[m]['test_f1_class0'] for m in results_oversampled.keys()],\n",
    "    'With Oversampling - Test Precision (Class 0)': [results_oversampled[m]['test_precision_class0'] for m in results_oversampled.keys()],\n",
    "    'With Oversampling - Test Recall (Class 0)': [results_oversampled[m]['test_recall_class0'] for m in results_oversampled.keys()],\n",
    "    'Without Oversampling - Test F1 (Class 0)': [results_no_oversampling[m]['test_f1_class0'] for m in results_no_oversampling.keys()],\n",
    "    'Without Oversampling - Test Precision (Class 0)': [results_no_oversampling[m]['test_precision_class0'] for m in results_no_oversampling.keys()],\n",
    "    'Without Oversampling - Test Recall (Class 0)': [results_no_oversampling[m]['test_recall_class0'] for m in results_no_oversampling.keys()],\n",
    "    'F1 Improvement': [results_oversampled[m]['test_f1_class0'] - results_no_oversampling[m]['test_f1_class0'] for m in results_oversampled.keys()],\n",
    "    'Recall Improvement': [results_oversampled[m]['test_recall_class0'] - results_no_oversampling[m]['test_recall_class0'] for m in results_oversampled.keys()],\n",
    "    'Precision Change': [results_oversampled[m]['test_precision_class0'] - results_no_oversampling[m]['test_precision_class0'] for m in results_oversampled.keys()]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"COMPARISON: WITH OVERSAMPLING vs WITHOUT OVERSAMPLING\")\n",
    "print(\"=\"*100)\n",
    "print(comparison_oversampling.to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "\n",
    "# Determine which approach is better for each model\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUMMARY: Which approach performs better?\")\n",
    "print(\"=\"*70)\n",
    "for model_name in results_oversampled.keys():\n",
    "    f1_with = results_oversampled[model_name]['test_f1_class0']\n",
    "    f1_without = results_no_oversampling[model_name]['test_f1_class0']\n",
    "    improvement = f1_with - f1_without\n",
    "    \n",
    "    if improvement > 0:\n",
    "        print(f\"{model_name}: Oversampling is BETTER (F1 improvement: +{improvement:.4f})\")\n",
    "    elif improvement < 0:\n",
    "        print(f\"{model_name}: No oversampling is BETTER (F1 difference: {improvement:.4f})\")\n",
    "    else:\n",
    "        print(f\"{model_name}: Both approaches perform equally\")\n",
    "\n",
    "# Find best overall approach\n",
    "best_f1_with = max([results_oversampled[m]['test_f1_class0'] for m in results_oversampled.keys()])\n",
    "best_f1_without = max([results_no_oversampling[m]['test_f1_class0'] for m in results_no_oversampling.keys()])\n",
    "\n",
    "print(f\"\\nBest Test F1 Score WITH oversampling: {best_f1_with:.4f}\")\n",
    "print(f\"Best Test F1 Score WITHOUT oversampling: {best_f1_without:.4f}\")\n",
    "\n",
    "if best_f1_with > best_f1_without:\n",
    "    print(f\"\\n OVERALL WINNER: Oversampling (improvement: +{best_f1_with - best_f1_without:.4f})\")\n",
    "elif best_f1_without > best_f1_with:\n",
    "    print(f\"\\n OVERALL WINNER: No oversampling (improvement: +{best_f1_without - best_f1_with:.4f})\")\n",
    "else:\n",
    "    print(f\"\\nBoth approaches perform equally\")\n",
    "\n",
    "# Calculate best individual model for ensemble comparison\n",
    "best_f1_individual = max(best_f1_with, best_f1_without)\n",
    "if best_f1_with >= best_f1_without:\n",
    "    best_individual_name = max(results_oversampled.keys(), key=lambda x: results_oversampled[x]['test_f1_class0'])\n",
    "    best_individual_results = results_oversampled[best_individual_name]\n",
    "else:\n",
    "    best_individual_name = max(results_no_oversampling.keys(), key=lambda x: results_no_oversampling[x]['test_f1_class0'])\n",
    "    best_individual_results = results_no_oversampling[best_individual_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a24506e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TESTING ENSEMBLE METHODS\n",
      "======================================================================\n",
      "\n",
      "Top performing models (sorted by Test F1 Score for Class 0):\n",
      "1. LightGBM (no_oversampling): 0.6284\n",
      "2. XGBoost (no_oversampling): 0.6127\n",
      "3. CatBoost (no_oversampling): 0.6014\n",
      "4. Gradient Boosting (no_oversampling): 0.5773\n",
      "5. AdaBoost (oversampled): 0.5773\n",
      "\n",
      "Selected 5 models for ensemble:\n",
      "1. LightGBM (no_oversampling): F1=0.6284\n",
      "2. XGBoost (no_oversampling): F1=0.6127\n",
      "3. CatBoost (no_oversampling): F1=0.6014\n",
      "4. Gradient Boosting (no_oversampling): F1=0.5773\n",
      "5. AdaBoost (oversampled): F1=0.5773\n",
      "\n",
      "Prepared 5 models for ensemble with their best hyperparameters\n"
     ]
    }
   ],
   "source": [
    "# Create ensemble methods using top-performing models\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TESTING ENSEMBLE METHODS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Identify top 3-5 models based on Test F1 Score for Class 0\n",
    "# Sort all models (both oversampled and non-oversampled) by performance\n",
    "all_model_scores = []\n",
    "\n",
    "# Add models from oversampled results\n",
    "for name in results_oversampled.keys():\n",
    "    all_model_scores.append({\n",
    "        'name': name,\n",
    "        'f1_score': results_oversampled[name]['test_f1_class0'],\n",
    "        'model': results_oversampled[name]['model'],\n",
    "        'source': 'oversampled'\n",
    "    })\n",
    "\n",
    "# Add models from non-oversampled results\n",
    "for name in results_no_oversampling.keys():\n",
    "    all_model_scores.append({\n",
    "        'name': name,\n",
    "        'f1_score': results_no_oversampling[name]['test_f1_class0'],\n",
    "        'model': results_no_oversampling[name]['model'],\n",
    "        'source': 'no_oversampling'\n",
    "    })\n",
    "\n",
    "# Sort by F1 score and get top models\n",
    "all_model_scores.sort(key=lambda x: x['f1_score'], reverse=True)\n",
    "\n",
    "print(\"\\nTop performing models (sorted by Test F1 Score for Class 0):\")\n",
    "for i, model_info in enumerate(all_model_scores[:5], 1):\n",
    "    print(f\"{i}. {model_info['name']} ({model_info['source']}): {model_info['f1_score']:.4f}\")\n",
    "\n",
    "# Select top 3-5 models for ensemble (diverse set)\n",
    "# Try to get models from different algorithms\n",
    "top_models_for_ensemble = []\n",
    "seen_types = set()\n",
    "\n",
    "for model_info in all_model_scores:\n",
    "    model_name = model_info['name']\n",
    "    # Get diverse models (avoid duplicates of same algorithm)\n",
    "    if model_name not in seen_types or len(top_models_for_ensemble) < 3:\n",
    "        top_models_for_ensemble.append(model_info)\n",
    "        seen_types.add(model_name)\n",
    "    if len(top_models_for_ensemble) >= 5:\n",
    "        break\n",
    "\n",
    "print(f\"\\nSelected {len(top_models_for_ensemble)} models for ensemble:\")\n",
    "for i, model_info in enumerate(top_models_for_ensemble, 1):\n",
    "    print(f\"{i}. {model_info['name']} ({model_info['source']}): F1={model_info['f1_score']:.4f}\")\n",
    "\n",
    "# Prepare models for ensemble - retrain with best hyperparameters\n",
    "from sklearn.base import clone\n",
    "\n",
    "ensemble_models = []\n",
    "for model_info in top_models_for_ensemble:\n",
    "    model_name = model_info['name']\n",
    "    source = model_info['source']\n",
    "    \n",
    "    # Get the best hyperparameters from the appropriate results dictionary\n",
    "    if source == 'oversampled':\n",
    "        best_params = results_oversampled[model_name]['best_params']\n",
    "    else:\n",
    "        best_params = results_no_oversampling[model_name]['best_params']\n",
    "    \n",
    "    # Get the base model and set hyperparameters\n",
    "    if model_name in base_models:\n",
    "        base_model = base_models[model_name]\n",
    "        # Clone and set parameters\n",
    "        model_for_ensemble = clone(base_model)\n",
    "        model_for_ensemble.set_params(**best_params)\n",
    "    else:\n",
    "        # For external libraries, clone the trained model\n",
    "        model_for_ensemble = clone(model_info['model'])\n",
    "    \n",
    "    ensemble_models.append((model_name, model_for_ensemble))\n",
    "\n",
    "print(f\"\\nPrepared {len(ensemble_models)} models for ensemble with their best hyperparameters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ddacefcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using original training data for ensembles\n",
      "Training data shape: (6280, 25)\n",
      "\n",
      "======================================================================\n",
      "1. VOTING CLASSIFIER (Hard Voting)\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bnoha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\bnoha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1 (Class 0): 0.7433\n",
      "Test F1 (Class 0): 0.5950\n",
      "Test Precision (Class 0): 0.9765\n",
      "Test Recall (Class 0): 0.4278\n",
      "\n",
      "======================================================================\n",
      "2. VOTING CLASSIFIER (Soft Voting)\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bnoha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\bnoha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1 (Class 0): 0.7504\n",
      "Test F1 (Class 0): 0.6175\n",
      "Test Precision (Class 0): 0.9670\n",
      "Test Recall (Class 0): 0.4536\n"
     ]
    }
   ],
   "source": [
    "# Train ensemble methods\n",
    "# Determine which training data to use based on best approach\n",
    "use_oversampling_ensemble = best_f1_with >= best_f1_without\n",
    "training_data_X = X_train_oversampled if use_oversampling_ensemble else X_train_processed\n",
    "training_data_y = y_train_oversampled if use_oversampling_ensemble else y_train\n",
    "\n",
    "print(f\"\\nUsing {'oversampled' if use_oversampling_ensemble else 'original'} training data for ensembles\")\n",
    "print(f\"Training data shape: {training_data_X.shape}\")\n",
    "\n",
    "# 1. Voting Classifier (Hard Voting)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"1. VOTING CLASSIFIER (Hard Voting)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "voting_hard = VotingClassifier(\n",
    "    estimators=ensemble_models,\n",
    "    voting='hard',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "voting_hard.fit(training_data_X, training_data_y)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_voting_hard = voting_hard.predict(X_train_processed)\n",
    "y_test_pred_voting_hard = voting_hard.predict(X_test_processed)\n",
    "\n",
    "# Calculate metrics\n",
    "train_f1_voting_hard = f1_score(y_train, y_train_pred_voting_hard, pos_label=0, zero_division=0)\n",
    "test_f1_voting_hard = f1_score(y_test, y_test_pred_voting_hard, pos_label=0, zero_division=0)\n",
    "test_precision_voting_hard = precision_score(y_test, y_test_pred_voting_hard, pos_label=0, zero_division=0)\n",
    "test_recall_voting_hard = recall_score(y_test, y_test_pred_voting_hard, pos_label=0, zero_division=0)\n",
    "\n",
    "print(f\"Train F1 (Class 0): {train_f1_voting_hard:.4f}\")\n",
    "print(f\"Test F1 (Class 0): {test_f1_voting_hard:.4f}\")\n",
    "print(f\"Test Precision (Class 0): {test_precision_voting_hard:.4f}\")\n",
    "print(f\"Test Recall (Class 0): {test_recall_voting_hard:.4f}\")\n",
    "\n",
    "# 2. Voting Classifier (Soft Voting) - if models support predict_proba\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"2. VOTING CLASSIFIER (Soft Voting)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    voting_soft = VotingClassifier(\n",
    "        estimators=ensemble_models,\n",
    "        voting='soft',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    voting_soft.fit(training_data_X, training_data_y)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_train_pred_voting_soft = voting_soft.predict(X_train_processed)\n",
    "    y_test_pred_voting_soft = voting_soft.predict(X_test_processed)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_f1_voting_soft = f1_score(y_train, y_train_pred_voting_soft, pos_label=0, zero_division=0)\n",
    "    test_f1_voting_soft = f1_score(y_test, y_test_pred_voting_soft, pos_label=0, zero_division=0)\n",
    "    test_precision_voting_soft = precision_score(y_test, y_test_pred_voting_soft, pos_label=0, zero_division=0)\n",
    "    test_recall_voting_soft = recall_score(y_test, y_test_pred_voting_soft, pos_label=0, zero_division=0)\n",
    "    \n",
    "    print(f\"Train F1 (Class 0): {train_f1_voting_soft:.4f}\")\n",
    "    print(f\"Test F1 (Class 0): {test_f1_voting_soft:.4f}\")\n",
    "    print(f\"Test Precision (Class 0): {test_precision_voting_soft:.4f}\")\n",
    "    print(f\"Test Recall (Class 0): {test_recall_voting_soft:.4f}\")\n",
    "    voting_soft_available = True\n",
    "except Exception as e:\n",
    "    print(f\"Soft voting failed: {e}\")\n",
    "    voting_soft_available = False\n",
    "    train_f1_voting_soft = 0\n",
    "    test_f1_voting_soft = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "79d0298c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "3. STACKING CLASSIFIER\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bnoha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\bnoha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1 (Class 0): 0.7942\n",
      "Test F1 (Class 0): 0.7165\n",
      "Test Precision (Class 0): 0.9055\n",
      "Test Recall (Class 0): 0.5928\n",
      "\n",
      "======================================================================\n",
      "ENSEMBLE COMPARISON WITH BEST INDIVIDUAL MODEL\n",
      "======================================================================\n",
      "\n",
      "Best Individual Model: LightGBM\n",
      "  Test F1 (Class 0): 0.6284\n",
      "\n",
      "Ensemble Methods:\n",
      "  Voting (Hard) - Test F1 (Class 0): 0.5950 (improvement: -0.0334)\n",
      "  Voting (Soft) - Test F1 (Class 0): 0.6175 (improvement: -0.0108)\n",
      "  Stacking - Test F1 (Class 0): 0.7165 (improvement: +0.0881)\n",
      "\n",
      "======================================================================\n",
      "DETAILED ENSEMBLE COMPARISON\n",
      "======================================================================\n",
      "               Method  Test F1 (Class 0)  Test Precision (Class 0)  Test Recall (Class 0)\n",
      "Best Individual Model           0.628378                  0.911765               0.479381\n",
      "        Voting (Hard)           0.594982                  0.976471               0.427835\n",
      "        Voting (Soft)           0.617544                  0.967033               0.453608\n",
      "             Stacking           0.716511                  0.905512               0.592784\n",
      "\n",
      "======================================================================\n",
      "BEST OVERALL METHOD\n",
      "======================================================================\n",
      " Stacking Classifier is the BEST (F1: 0.7165)\n",
      "  Improvement over best individual: +0.0881\n"
     ]
    }
   ],
   "source": [
    "# 3. Stacking Classifier\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"3. STACKING CLASSIFIER\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Use Logistic Regression as the meta-learner\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "stacking = StackingClassifier(\n",
    "    estimators=ensemble_models,\n",
    "    final_estimator=LogisticRegression(random_state=42, max_iter=1000),\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "stacking.fit(training_data_X, training_data_y)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_stacking = stacking.predict(X_train_processed)\n",
    "y_test_pred_stacking = stacking.predict(X_test_processed)\n",
    "\n",
    "# Calculate metrics\n",
    "train_f1_stacking = f1_score(y_train, y_train_pred_stacking, pos_label=0, zero_division=0)\n",
    "test_f1_stacking = f1_score(y_test, y_test_pred_stacking, pos_label=0, zero_division=0)\n",
    "test_precision_stacking = precision_score(y_test, y_test_pred_stacking, pos_label=0, zero_division=0)\n",
    "test_recall_stacking = recall_score(y_test, y_test_pred_stacking, pos_label=0, zero_division=0)\n",
    "\n",
    "print(f\"Train F1 (Class 0): {train_f1_stacking:.4f}\")\n",
    "print(f\"Test F1 (Class 0): {test_f1_stacking:.4f}\")\n",
    "print(f\"Test Precision (Class 0): {test_precision_stacking:.4f}\")\n",
    "print(f\"Test Recall (Class 0): {test_recall_stacking:.4f}\")\n",
    "\n",
    "# Compare ensemble methods with best individual model\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ENSEMBLE COMPARISON WITH BEST INDIVIDUAL MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "best_individual_f1 = best_f1_individual\n",
    "\n",
    "print(f\"\\nBest Individual Model: {best_individual_name}\")\n",
    "print(f\"  Test F1 (Class 0): {best_individual_f1:.4f}\")\n",
    "\n",
    "print(f\"\\nEnsemble Methods:\")\n",
    "print(f\"  Voting (Hard) - Test F1 (Class 0): {test_f1_voting_hard:.4f} (improvement: {test_f1_voting_hard - best_individual_f1:+.4f})\")\n",
    "if voting_soft_available:\n",
    "    print(f\"  Voting (Soft) - Test F1 (Class 0): {test_f1_voting_soft:.4f} (improvement: {test_f1_voting_soft - best_individual_f1:+.4f})\")\n",
    "print(f\"  Stacking - Test F1 (Class 0): {test_f1_stacking:.4f} (improvement: {test_f1_stacking - best_individual_f1:+.4f})\")\n",
    "\n",
    "# Create comparison DataFrame\n",
    "ensemble_comparison = pd.DataFrame({\n",
    "    'Method': ['Best Individual Model', 'Voting (Hard)', 'Voting (Soft)', 'Stacking'],\n",
    "    'Test F1 (Class 0)': [\n",
    "        best_individual_f1,\n",
    "        test_f1_voting_hard,\n",
    "        test_f1_voting_soft if voting_soft_available else None,\n",
    "        test_f1_stacking\n",
    "    ],\n",
    "    'Test Precision (Class 0)': [\n",
    "        best_individual_results['test_precision_class0'],\n",
    "        test_precision_voting_hard,\n",
    "        test_precision_voting_soft if voting_soft_available else None,\n",
    "        test_precision_stacking\n",
    "    ],\n",
    "    'Test Recall (Class 0)': [\n",
    "        best_individual_results['test_recall_class0'],\n",
    "        test_recall_voting_hard,\n",
    "        test_recall_voting_soft if voting_soft_available else None,\n",
    "        test_recall_stacking\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Remove rows with None values\n",
    "ensemble_comparison = ensemble_comparison.dropna()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DETAILED ENSEMBLE COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "print(ensemble_comparison.to_string(index=False))\n",
    "\n",
    "# Find best overall method\n",
    "best_ensemble_f1 = max([test_f1_voting_hard, test_f1_stacking] + ([test_f1_voting_soft] if voting_soft_available else []))\n",
    "best_overall_f1 = max(best_individual_f1, best_ensemble_f1)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"BEST OVERALL METHOD\")\n",
    "print(f\"{'='*70}\")\n",
    "if best_overall_f1 > best_individual_f1:\n",
    "    if best_ensemble_f1 == test_f1_stacking:\n",
    "        print(f\" Stacking Classifier is the BEST (F1: {best_overall_f1:.4f})\")\n",
    "        print(f\"  Improvement over best individual: +{best_overall_f1 - best_individual_f1:.4f}\")\n",
    "    elif best_ensemble_f1 == test_f1_voting_soft and voting_soft_available:\n",
    "        print(f\" Voting (Soft) is the BEST (F1: {best_overall_f1:.4f})\")\n",
    "        print(f\"  Improvement over best individual: +{best_overall_f1 - best_individual_f1:.4f}\")\n",
    "    else:\n",
    "        print(f\" Voting (Hard) is the BEST (F1: {best_overall_f1:.4f})\")\n",
    "        print(f\"  Improvement over best individual: +{best_overall_f1 - best_individual_f1:.4f}\")\n",
    "else:\n",
    "    print(f\" Best Individual Model ({best_individual_name}) remains the BEST (F1: {best_overall_f1:.4f})\")\n",
    "    print(f\"  Ensembles did not improve performance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ab2c3f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "BEST OVERALL MODEL (Selected by Test F1 Score for Class 0 - Non-Converters)\n",
      "======================================================================\n",
      "\n",
      " BEST METHOD: Stacking Classifier (Ensemble)\n",
      "  Test F1 Score (Class 0): 0.7165\n",
      "  Improvement over best individual model (LightGBM): +0.0881\n",
      "\n",
      "======================================================================\n",
      "Ensemble Details:\n",
      "======================================================================\n",
      "  Base Models: LightGBM, XGBoost, CatBoost, Gradient Boosting, AdaBoost\n",
      "  Meta-learner: Logistic Regression\n",
      "  Training Approach: WITHOUT Oversampling\n",
      "\n",
      "======================================================================\n",
      "Test Set Performance for Class 0 (Non-Converters):\n",
      "======================================================================\n",
      "  Test Precision (Class 0): 0.9055\n",
      "  Test Recall (Class 0): 0.5928\n",
      "  Test F1 Score (Class 0): 0.7165\n",
      "\n",
      "Other Test Set Metrics:\n",
      "  Test Accuracy: 0.9421\n",
      "  Test F1 Score (Class 1): 0.9677\n",
      "  Test ROC-AUC: 0.8117\n",
      "\n",
      "======================================================================\n",
      "Comparison with Best Individual Model (LightGBM):\n",
      "======================================================================\n",
      "  Best Individual Model - Test F1 (Class 0): 0.6284\n",
      "  Best Ensemble Method - Test F1 (Class 0): 0.7165\n",
      "  Improvement: +0.0881\n",
      "\n",
      "======================================================================\n",
      "Detailed Classification Report for Stacking Classifier\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bnoha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\bnoha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.59      0.72       194\n",
      "           1       0.95      0.99      0.97      1377\n",
      "\n",
      "    accuracy                           0.94      1571\n",
      "   macro avg       0.93      0.79      0.84      1571\n",
      "weighted avg       0.94      0.94      0.94      1571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Identify the best overall model (including ensembles) based on Test F1 Score for Class 0 (non-converters)\n",
    "# Use the comparison from the ensemble cell above to determine the best overall method\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"BEST OVERALL MODEL (Selected by Test F1 Score for Class 0 - Non-Converters)\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Check if best overall is an ensemble or individual model\n",
    "if best_overall_f1 > best_individual_f1:\n",
    "    # Best is an ensemble method\n",
    "    if best_ensemble_f1 == test_f1_stacking:\n",
    "        best_method_name = \"Stacking Classifier\"\n",
    "        best_method_type = \"Ensemble\"\n",
    "        best_model_obj = stacking\n",
    "        best_method_f1 = test_f1_stacking\n",
    "        best_method_precision = test_precision_stacking\n",
    "        best_method_recall = test_recall_stacking\n",
    "        \n",
    "        # Get predictions for classification report\n",
    "        y_test_pred_best = stacking.predict(X_test_processed)\n",
    "        y_test_proba_best = stacking.predict_proba(X_test_processed)[:, 1]\n",
    "        \n",
    "        print(f\"\\n BEST METHOD: {best_method_name} (Ensemble)\")\n",
    "        print(f\"  Test F1 Score (Class 0): {best_method_f1:.4f}\")\n",
    "        print(f\"  Improvement over best individual model ({best_individual_name}): +{best_method_f1 - best_individual_f1:.4f}\")\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"Ensemble Details:\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"  Base Models: {', '.join([name for name, _ in ensemble_models])}\")\n",
    "        print(f\"  Meta-learner: Logistic Regression\")\n",
    "        print(f\"  Training Approach: {'WITH Oversampling (SMOTE)' if use_oversampling_ensemble else 'WITHOUT Oversampling'}\")\n",
    "        \n",
    "    elif best_ensemble_f1 == test_f1_voting_soft and voting_soft_available:\n",
    "        best_method_name = \"Voting Classifier (Soft)\"\n",
    "        best_method_type = \"Ensemble\"\n",
    "        best_model_obj = voting_soft\n",
    "        best_method_f1 = test_f1_voting_soft\n",
    "        best_method_precision = test_precision_voting_soft\n",
    "        best_method_recall = test_recall_voting_soft\n",
    "        \n",
    "        # Get predictions for classification report\n",
    "        y_test_pred_best = voting_soft.predict(X_test_processed)\n",
    "        y_test_proba_best = voting_soft.predict_proba(X_test_processed)[:, 1]\n",
    "        \n",
    "        print(f\"\\n BEST METHOD: {best_method_name} (Ensemble)\")\n",
    "        print(f\"  Test F1 Score (Class 0): {best_method_f1:.4f}\")\n",
    "        print(f\"  Improvement over best individual model ({best_individual_name}): +{best_method_f1 - best_individual_f1:.4f}\")\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"Ensemble Details:\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"  Base Models: {', '.join([name for name, _ in ensemble_models])}\")\n",
    "        print(f\"  Voting Method: Soft (probability-weighted)\")\n",
    "        print(f\"  Training Approach: {'WITH Oversampling (SMOTE)' if use_oversampling_ensemble else 'WITHOUT Oversampling'}\")\n",
    "        \n",
    "    else:\n",
    "        best_method_name = \"Voting Classifier (Hard)\"\n",
    "        best_method_type = \"Ensemble\"\n",
    "        best_model_obj = voting_hard\n",
    "        best_method_f1 = test_f1_voting_hard\n",
    "        best_method_precision = test_precision_voting_hard\n",
    "        best_method_recall = test_recall_voting_hard\n",
    "        \n",
    "        # Get predictions for classification report\n",
    "        y_test_pred_best = voting_hard.predict(X_test_processed)\n",
    "        y_test_proba_best = voting_hard.predict_proba(X_test_processed)[:, 1]\n",
    "        \n",
    "        print(f\"\\n BEST METHOD: {best_method_name} (Ensemble)\")\n",
    "        print(f\"  Test F1 Score (Class 0): {best_method_f1:.4f}\")\n",
    "        print(f\"  Improvement over best individual model ({best_individual_name}): +{best_method_f1 - best_individual_f1:.4f}\")\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"Ensemble Details:\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"  Base Models: {', '.join([name for name, _ in ensemble_models])}\")\n",
    "        print(f\"  Voting Method: Hard (majority vote)\")\n",
    "        print(f\"  Training Approach: {'WITH Oversampling (SMOTE)' if use_oversampling_ensemble else 'WITHOUT Oversampling'}\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Test Set Performance for Class 0 (Non-Converters):\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"  Test Precision (Class 0): {best_method_precision:.4f}\")\n",
    "    print(f\"  Test Recall (Class 0): {best_method_recall:.4f}\")\n",
    "    print(f\"  Test F1 Score (Class 0): {best_method_f1:.4f}\")\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    test_accuracy_best = accuracy_score(y_test, y_test_pred_best)\n",
    "    test_f1_class1_best = f1_score(y_test, y_test_pred_best, pos_label=1, zero_division=0)\n",
    "    test_roc_auc_best = roc_auc_score(y_test, y_test_proba_best)\n",
    "    \n",
    "    print(f\"\\nOther Test Set Metrics:\")\n",
    "    print(f\"  Test Accuracy: {test_accuracy_best:.4f}\")\n",
    "    print(f\"  Test F1 Score (Class 1): {test_f1_class1_best:.4f}\")\n",
    "    print(f\"  Test ROC-AUC: {test_roc_auc_best:.4f}\")\n",
    "    \n",
    "    # Show comparison with best individual model\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Comparison with Best Individual Model ({best_individual_name}):\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"  Best Individual Model - Test F1 (Class 0): {best_individual_f1:.4f}\")\n",
    "    print(f\"  Best Ensemble Method - Test F1 (Class 0): {best_method_f1:.4f}\")\n",
    "    print(f\"  Improvement: +{best_method_f1 - best_individual_f1:.4f}\")\n",
    "    \n",
    "else:\n",
    "    # Best is an individual model\n",
    "    best_f1_with = max([results_oversampled[m]['test_f1_class0'] for m in results_oversampled.keys()])\n",
    "    best_f1_without = max([results_no_oversampling[m]['test_f1_class0'] for m in results_no_oversampling.keys()])\n",
    "    \n",
    "    # Determine which approach is better and get the best model\n",
    "    if best_f1_with >= best_f1_without:\n",
    "        use_oversampling = True\n",
    "        best_f1_score = best_f1_with\n",
    "        best_model_name = max(results_oversampled.keys(), key=lambda x: results_oversampled[x]['test_f1_class0'])\n",
    "        best_results = results_oversampled[best_model_name]\n",
    "    else:\n",
    "        use_oversampling = False\n",
    "        best_f1_score = best_f1_without\n",
    "        best_model_name = max(results_no_oversampling.keys(), key=lambda x: results_no_oversampling[x]['test_f1_class0'])\n",
    "        best_results = results_no_oversampling[best_model_name]\n",
    "    \n",
    "    best_model_obj = best_results['model']\n",
    "    \n",
    "    print(f\"\\n BEST METHOD: {best_model_name} (Individual Model)\")\n",
    "    print(f\"  Training Approach: {'WITH Oversampling (SMOTE)' if use_oversampling else 'WITHOUT Oversampling'}\")\n",
    "    print(f\"  Test F1 Score (Class 0): {best_f1_score:.4f}\")\n",
    "    \n",
    "    print(f\"\\nBest Hyperparameters:\")\n",
    "    for param, value in best_results['best_params'].items():\n",
    "        print(f\"  {param}: {value}\")\n",
    "    \n",
    "    print(f\"\\nCross-Validation F1 Score (Class 0): {best_results['cv_f1_score_class0']:.4f}\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Test Set Performance for Class 0 (Non-Converters):\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"  Test Precision (Class 0): {best_results['test_precision_class0']:.4f}\")\n",
    "    print(f\"  Test Recall (Class 0): {best_results['test_recall_class0']:.4f}\")\n",
    "    print(f\"  Test F1 Score (Class 0): {best_results['test_f1_class0']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nOther Test Set Metrics:\")\n",
    "    print(f\"  Test Accuracy: {best_results['test_accuracy']:.4f}\")\n",
    "    print(f\"  Test F1 Score (Class 1): {best_results['test_f1_class1']:.4f}\")\n",
    "    print(f\"  Test ROC-AUC: {best_results['test_roc_auc']:.4f}\")\n",
    "    \n",
    "    # Show comparison with the other approach\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Comparison with {'WITHOUT' if use_oversampling else 'WITH'} Oversampling:\")\n",
    "    print(f\"{'='*70}\")\n",
    "    if use_oversampling:\n",
    "        other_results = results_no_oversampling[best_model_name]\n",
    "        print(f\"  Without Oversampling - Test F1 (Class 0): {other_results['test_f1_class0']:.4f}\")\n",
    "        print(f\"  Improvement from Oversampling: +{best_f1_score - other_results['test_f1_class0']:.4f}\")\n",
    "    else:\n",
    "        other_results = results_oversampled[best_model_name]\n",
    "        print(f\"  With Oversampling - Test F1 (Class 0): {other_results['test_f1_class0']:.4f}\")\n",
    "        print(f\"  Improvement without Oversampling: +{best_f1_score - other_results['test_f1_class0']:.4f}\")\n",
    "    \n",
    "    # Get predictions for classification report\n",
    "    y_test_pred_best = best_model_obj.predict(X_test_processed)\n",
    "    \n",
    "    # Show comparison with ensemble methods\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Comparison with Ensemble Methods:\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"  Best Individual Model - Test F1 (Class 0): {best_f1_score:.4f}\")\n",
    "    print(f\"  Voting (Hard) - Test F1 (Class 0): {test_f1_voting_hard:.4f}\")\n",
    "    if voting_soft_available:\n",
    "        print(f\"  Voting (Soft) - Test F1 (Class 0): {test_f1_voting_soft:.4f}\")\n",
    "    print(f\"  Stacking - Test F1 (Class 0): {test_f1_stacking:.4f}\")\n",
    "    print(f\"  Note: Individual model performed better than all ensemble methods\")\n",
    "\n",
    "# Print detailed classification report for best model\n",
    "print(f\"\\n{'='*70}\")\n",
    "if best_overall_f1 > best_individual_f1:\n",
    "    print(f\"Detailed Classification Report for {best_method_name}\")\n",
    "else:\n",
    "    print(f\"Detailed Classification Report for {best_model_name}\")\n",
    "print(f\"{'='*70}\")\n",
    "print(classification_report(y_test, y_test_pred_best))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1ee2aa",
   "metadata": {},
   "source": [
    "<h2>Conclusion and Next Steps</h2>\n",
    "\n",
    "An ensemble stacking classifier of the following performed the best: LightGBM, XGBoost, CatBoost, Gradient Boosting, and AdaBoost.\n",
    "\n",
    "Our initial goal was to predict non-converters, and we did this with an F1 score of 0.72. This is likely the more valuable use case, as historical conversion rate is alreadyhigh at 88%. We can add non-converting users to an exclusion audience, which may help to increase efficiency for the campaign. Or, experiments could be run with different marketing strategies to see how to increase the conversion rate for these users that we predict will not convert with the existing strategy.\n",
    "\n",
    "Still, F1 score for predicting converting users was also high at 0.97, so the model does increase our intelligence at predicting the majority case as well.\n",
    "\n",
    "To further improve the model, particularly for the non-converting user case, these strategies could be tested:\n",
    "<ul>\n",
    "<li>Adding aggregation features like gender x age group, total page visits, time spent per page, etc\n",
    "<li>Removing low importance features, identified by mutual information\n",
    "<li>More robust hyperparameter tuning with Optuna\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
